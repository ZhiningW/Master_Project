---
title: "Model Selection in Factor Analysis"
author: "Zhining Wang"
supervisors:
  - "Dr. Emi Tanaka"
  - "Dr. Qinian Jin (co-supervisor)"
date: today
format: 
  pdf: 
    documentclass: amsart
    fontsize: 12pt
    template-partials:
      - partials/before-body.tex
      - partials/after-body.tex
    include-in-header:
      text: |
        \usepackage{fullpage}
        \usepackage{enumitem}
bibliography: ref.bib
editor: 
  markdown: 
    wrap: 72
---
# Introduction of Factor Analytic Models
Factor analysis is a statistical method which attempts to use fewer
underlying factors to explain the correlation between a large set of
observed variables. Suppose we have an observable random vector $\boldsymbol{y}_i\in \mathbb{R}^p$ for the $i$-th subject
with mean $\mathbb{E}(\boldsymbol{y}_i)=\boldsymbol{\mu}$ and variance
$\mathbb{V}(\boldsymbol{y}_i)=\boldsymbol{\Sigma}$. Then a $k$-order factor analysis model
for $\boldsymbol{y}_i$ can be given by \begin{equation}
\boldsymbol{y}_i=\boldsymbol{\mu}+\boldsymbol{\Lambda} \boldsymbol{f}_i+\boldsymbol{\epsilon}_i,
\end{equation} where $\boldsymbol{\Lambda} \in \mathbb{R}^{p \times k}$,   $\boldsymbol{f}_i \in \mathbb{R}^{k}$ is and $\boldsymbol{\epsilon}_i \in \mathbb{R}^{p}$ are called the _loading matrix_, _common factors_  and _unique (or specific) factors_, respectively. The order $k$ is usually much smaller than $p$. For simplicity, we can assume that $\boldsymbol{\mu} = \boldsymbol{0}_p$.
We also assume that the common factors and the unique factors are independent. We aim to estimate a _sparse_ loading matrix as well as estimate the diagonal covariance matrix of the unique factor.

# Current Work Results
I have completed the introduction to the factor analysis model and reviewed the traditional two-step procedure for obtaining the sparse loading matrix. However, this traditional method has been criticized for potentially causing overfitting and producing overly dense solutions. I conducted a small simulation to demonstrate these issues. Following this, I explored Expecation-Maximisation (EM) algorithm and penalised likelihood approaches to fitting factor analytic models, including a brief proof of the algorithm's correctness. I detailed extensively procedures for both the E-step and the M-step in the aforementioned algorithm. In the M-step, I employed a proximal gradient method. I implemented the algorithm (that is still in work-in-progress) in the statistical software, R.

# Future Expectations

This semester, I will continue polishing my code, including bug fixes and stability enhancements. I will also focus on the simulation settings, exploring various interesting aspects such as initialization strategies, parameter tuning, and order selection. I plan to implement these elements using R and visualize the results in my thesis. Additionally, I will discuss the results and highlight the limitations of the model or algorithm. I intend to allocate at least a month to polish my notations, language, and typesetting.
